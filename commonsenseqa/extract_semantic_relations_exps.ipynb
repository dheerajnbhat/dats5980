{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27910273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "from gradio_client import Client\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0deb14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://cstr-conceptnet-normalized.hf.space âœ”\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"cstr/conceptnet_normalized\")\n",
    "\n",
    "relations = [\n",
    "            'RelatedTo','IsA','PartOf','HasA','UsedFor','CapableOf','AtLocation',\n",
    "            'Causes','HasSubevent','HasFirstSubevent','HasLastSubevent',\n",
    "            'HasPrerequisite','HasProperty','MotivatedByGoal','ObstructedBy',\n",
    "            'Desires','CreatedBy','Synonym','Antonym','DistinctFrom','DerivedFrom',\n",
    "            'SymbolOf','DefinedAs','MannerOf','LocatedNear','HasContext','SimilarTo',\n",
    "            'EtymologicallyRelatedTo','EtymologicallyDerivedFrom','CausesDesire',\n",
    "            'MadeOf','ReceivesAction','ExternalURL','NotDesires','NotUsedFor',\n",
    "            'NotCapableOf','NotHasProperty'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decf2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conceptnet_profile(word, relations):\n",
    "    result = client.predict(\n",
    "        word=word,\n",
    "        lang=\"en\",\n",
    "        selected_relations=relations,\n",
    "        api_name=\"/get_semantic_profile\"\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conceptnet_profile(profile_text):\n",
    "    \"\"\"\n",
    "    Parse ConceptNet semantic profile text into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        profile_text: String output from get_conceptnet_profile\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with relation types as keys and list of (word, score) tuples as values.\n",
    "        Only includes relations that have values, sorted by score in descending order.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # Extract the queried word from the header\n",
    "    # Pattern: # ðŸ§  Semantic Profile: 'word' (EN)\n",
    "    header_match = re.search(r\"# ðŸ§  Semantic Profile: '([^']+)'\", profile_text)\n",
    "    queried_word = header_match.group(1) if header_match else None\n",
    "    \n",
    "    # Normalize the queried word for comparison (both space and underscore versions)\n",
    "    if queried_word:\n",
    "        queried_normalized_space = queried_word.replace('_', ' ')\n",
    "        queried_normalized_underscore = queried_word.replace(' ', '_')\n",
    "    else:\n",
    "        queried_normalized_space = None\n",
    "        queried_normalized_underscore = None\n",
    "    \n",
    "    # Split by relation headers (## RelationType)\n",
    "    sections = re.split(r'## (\\w+)', profile_text)\n",
    "    \n",
    "    # sections[0] is the header before first relation, then alternates between relation name and content\n",
    "    for i in range(1, len(sections), 2):\n",
    "        relation = sections[i]\n",
    "        content = sections[i + 1] if i + 1 < len(sections) else \"\"\n",
    "        \n",
    "        # Temporary list for this relation\n",
    "        relation_list = []\n",
    "        \n",
    "        # Find all relation entries\n",
    "        # Pattern: - *word1* or **word1** RelationType â†’ *word2* or **word2** `[score]`\n",
    "        pattern = r'-\\s+(?:\\*\\*?([^*]+?)\\*\\*?)\\s+\\w+\\s+â†’\\s+(?:\\*\\*?([^*]+?)\\*\\*?)\\s+`\\[([0-9.]+)\\]`'\n",
    "        matches = re.findall(pattern, content)\n",
    "        \n",
    "        for match in matches:\n",
    "            word1, word2, score = match\n",
    "            # Remove any extra whitespace\n",
    "            word1 = word1.strip()\n",
    "            word2 = word2.strip()\n",
    "            score = float(score)\n",
    "            \n",
    "            # Check if either word matches the queried word (in either format)\n",
    "            def is_queried_word(word):\n",
    "                if not queried_word:\n",
    "                    return False\n",
    "                word_space = word.replace('_', ' ')\n",
    "                word_underscore = word.replace(' ', '_')\n",
    "                return (word == queried_word or \n",
    "                        word_space == queried_normalized_space or \n",
    "                        word_underscore == queried_normalized_underscore)\n",
    "            \n",
    "            # Determine which word is NOT the queried word\n",
    "            if is_queried_word(word1):\n",
    "                target_word = word2\n",
    "            elif is_queried_word(word2):\n",
    "                target_word = word1\n",
    "            else:\n",
    "                # If neither matches exactly, prefer word1 (usually the related concept)\n",
    "                target_word = word1\n",
    "            \n",
    "            relation_list.append((target_word, score))\n",
    "        \n",
    "        # Only add to result if there are values, and sort by score descending\n",
    "        if relation_list:\n",
    "            # Sort by score (second element of tuple) in descending order\n",
    "            relation_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            result[relation] = relation_list\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptnet_text = get_conceptnet_profile(\"revolving door\", relations)\n",
    "conceptnet_data = parse_conceptnet_profile(conceptnet_text)\n",
    "\n",
    "# conceptnet_text = get_conceptnet_profile(\"revolving_door\", relations)\n",
    "# conceptnet_data = parse_conceptnet_profile(conceptnet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56e6e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RelatedTo': [('drehtÃ¼r', 1.0),\n",
       "  ('revolving doors', 1.0),\n",
       "  ('tourniquet', 1.0),\n",
       "  ('bussola', 1.0)],\n",
       " 'UsedFor': [('entering building', 3.464),\n",
       "  ('enter building', 1.0),\n",
       "  ('exiting building', 1.0),\n",
       "  ('getting into building', 1.0)],\n",
       " 'AtLocation': [('lobby', 2.0),\n",
       "  ('bank', 1.0),\n",
       "  ('building', 1.0),\n",
       "  ('department store', 1.0),\n",
       "  ('entrance to building', 1.0),\n",
       "  ('hotel lobby', 1.0),\n",
       "  ('mall', 1.0)],\n",
       " 'Synonym': [('drehtÃ¼r', 1.0)]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptnet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "I have relations extracted from the conceptnet for a question_concept, which looks like this:\n",
    "\n",
    "conceptnet_data = {'RelatedTo': [('drehtÃ¼r', 1.0),\n",
    "  ('revolving doors', 1.0),\n",
    "  ('tourniquet', 1.0),\n",
    "  ('bussola', 1.0)],\n",
    " 'UsedFor': [('entering building', 3.464),\n",
    "  ('enter building', 1.0),\n",
    "  ('exiting building', 1.0),\n",
    "  ('getting into building', 1.0)],\n",
    " 'AtLocation': [('lobby', 2.0),\n",
    "  ('bank', 1.0),\n",
    "  ('building', 1.0),\n",
    "  ('department store', 1.0),\n",
    "  ('entrance to building', 1.0),\n",
    "  ('hotel lobby', 1.0),\n",
    "  ('mall', 1.0)],\n",
    " 'Synonym': [('drehtÃ¼r', 1.0)]}\n",
    "\n",
    "now for the given question, and choices\n",
    "\n",
    "question=  \"A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\",\n",
    "question_concept = \"revolving door\",\n",
    "choices = [\n",
    "    \"bank\",\n",
    "    \"library\",\n",
    "    \"department store\",\n",
    "    \"mall\",\n",
    "    \"new york\"\n",
    "]\n",
    "\n",
    "I need to rank the choices based on their relevance to the question_concept, question using the conceptnet_data. How can I do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "129af1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_choices_by_relevance(conceptnet_data, choices):\n",
    "    \"\"\"\n",
    "    Rank answer choices based on their presence in ConceptNet relations.\n",
    "    Uses only the weights provided in ConceptNet data.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        choices: List of answer choices to rank\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (choice, score, matching_info) sorted by score descending\n",
    "    \"\"\"\n",
    "    choice_scores = {}\n",
    "    \n",
    "    for choice in choices:\n",
    "        score = 0\n",
    "        matching_info = []\n",
    "        choice_lower = choice.lower().strip()\n",
    "        choice_words = set(choice_lower.split())\n",
    "        \n",
    "        # Check each relation type in conceptnet_data\n",
    "        for relation_type, concepts in conceptnet_data.items():\n",
    "            for concept, concept_weight in concepts:\n",
    "                concept_lower = concept.lower().strip()\n",
    "                concept_words = set(concept_lower.split())\n",
    "                \n",
    "                match_score = 0\n",
    "                match_type = None\n",
    "                \n",
    "                # Exact match\n",
    "                if choice_lower == concept_lower:\n",
    "                    match_score = concept_weight\n",
    "                    match_type = \"exact\"\n",
    "                \n",
    "                # Choice is substring of concept\n",
    "                elif choice_lower in concept_lower:\n",
    "                    match_score = concept_weight * 0.8\n",
    "                    match_type = \"substring\"\n",
    "                \n",
    "                # Concept is substring of choice\n",
    "                elif concept_lower in choice_lower:\n",
    "                    match_score = concept_weight * 0.6\n",
    "                    match_type = \"contains\"\n",
    "                \n",
    "                # Word overlap for multi-word phrases\n",
    "                else:\n",
    "                    overlap = choice_words & concept_words\n",
    "                    if overlap:\n",
    "                        overlap_ratio = len(overlap) / max(len(choice_words), len(concept_words))\n",
    "                        match_score = concept_weight * overlap_ratio * 0.5\n",
    "                        match_type = \"word_overlap\"\n",
    "                \n",
    "                if match_score > 0:\n",
    "                    score += match_score\n",
    "                    matching_info.append({\n",
    "                        'relation': relation_type,\n",
    "                        'concept': concept,\n",
    "                        'weight': concept_weight,\n",
    "                        'score': match_score,\n",
    "                        'type': match_type\n",
    "                    })\n",
    "        \n",
    "        choice_scores[choice] = (score, matching_info)\n",
    "    \n",
    "    # Sort by score descending\n",
    "    ranked_choices = sorted(\n",
    "        [(choice, score, info) for choice, (score, info) in choice_scores.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return ranked_choices\n",
    "\n",
    "\n",
    "def get_top_choice(conceptnet_data, choices):\n",
    "    \"\"\"\n",
    "    Get the top-ranked choice.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        choices: List of answer choices to rank\n",
    "    \n",
    "    Returns:\n",
    "        The top-ranked choice (string)\n",
    "    \"\"\"\n",
    "    ranked = rank_choices_by_relevance(conceptnet_data, choices)\n",
    "    return ranked[0][0] if ranked else choices[0]\n",
    "\n",
    "\n",
    "def get_ranked_choices(conceptnet_data, choices):\n",
    "    \"\"\"\n",
    "    Get just the list of choices in ranked order.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        choices: List of answer choices to rank\n",
    "    \n",
    "    Returns:\n",
    "        List of choices sorted by relevance score\n",
    "    \"\"\"\n",
    "    ranked = rank_choices_by_relevance(conceptnet_data, choices)\n",
    "    return [choice for choice, _, _ in ranked]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Choices:\n",
      "================================================================================\n",
      "\n",
      "1. BANK (Score: 1.00)\n",
      "   Matches:\n",
      "   - AtLocation: 'bank' (weight: 1.00, match: exact)\n",
      "\n",
      "2. DEPARTMENT STORE (Score: 1.00)\n",
      "   Matches:\n",
      "   - AtLocation: 'department store' (weight: 1.00, match: exact)\n",
      "\n",
      "3. MALL (Score: 1.00)\n",
      "   Matches:\n",
      "   - AtLocation: 'mall' (weight: 1.00, match: exact)\n",
      "\n",
      "4. LIBRARY (Score: 0.00)\n",
      "   No matches in ConceptNet data\n",
      "\n",
      "5. NEW YORK (Score: 0.00)\n",
      "   No matches in ConceptNet data\n",
      "\n",
      "================================================================================\n",
      "Ranked order: ['bank', 'department store', 'mall', 'library', 'new york']\n",
      "Top choice: bank\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    conceptnet_data = {\n",
    "        'RelatedTo': [('drehtÃ¼r', 1.0),\n",
    "                      ('revolving doors', 1.0),\n",
    "                      ('tourniquet', 1.0),\n",
    "                      ('bussola', 1.0)],\n",
    "        'UsedFor': [('entering building', 3.464),\n",
    "                    ('enter building', 1.0),\n",
    "                    ('exiting building', 1.0),\n",
    "                    ('getting into building', 1.0)],\n",
    "        'AtLocation': [('lobby', 2.0),\n",
    "                       ('bank', 1.0),\n",
    "                       ('building', 1.0),\n",
    "                       ('department store', 1.0),\n",
    "                       ('entrance to building', 1.0),\n",
    "                       ('hotel lobby', 1.0),\n",
    "                       ('mall', 1.0)],\n",
    "        'Synonym': [('drehtÃ¼r', 1.0)]\n",
    "    }\n",
    "    \n",
    "    choices = [\"bank\", \"library\", \"department store\", \"mall\", \"new york\"]\n",
    "    \n",
    "    # Get full ranking with scores\n",
    "    ranked = rank_choices_by_relevance(conceptnet_data, choices)\n",
    "    \n",
    "    print(\"Ranked Choices:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, (choice, score, info) in enumerate(ranked, 1):\n",
    "        print(f\"\\n{i}. {choice.upper()} (Score: {score:.2f})\")\n",
    "        if info:\n",
    "            print(f\"   Matches:\")\n",
    "            for match in sorted(info, key=lambda x: x['score'], reverse=True)[:3]:\n",
    "                print(f\"   - {match['relation']}: '{match['concept']}' \"\n",
    "                      f\"(weight: {match['weight']:.2f}, match: {match['type']})\")\n",
    "        else:\n",
    "            print(f\"   No matches in ConceptNet data\")\n",
    "    \n",
    "    # Simple outputs\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Ranked order:\", get_ranked_choices(conceptnet_data, choices))\n",
    "    print(\"Top choice:\", get_top_choice(conceptnet_data, choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bc705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8503a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b10e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "def get_embeddings(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of texts.\n",
    "    You can use sentence-transformers, OpenAI, or any other embedding model.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings to embed\n",
    "        model_name: Name of the embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "    # Example using sentence-transformers (install: pip install sentence-transformers)\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def rank_choices_semantic(\n",
    "    conceptnet_data: Dict[str, List[Tuple[str, float]]], \n",
    "    question: str,\n",
    "    choices: List[str],\n",
    "    model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ") -> List[Tuple[str, float, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Rank choices using semantic similarity between question and ConceptNet relations.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        question: The question text\n",
    "        choices: List of answer choices to rank\n",
    "        model_name: Embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (choice, score, details) sorted by score descending\n",
    "    \"\"\"\n",
    "    # Get question embedding\n",
    "    question_embedding = get_embeddings([question], model_name)[0]\n",
    "    \n",
    "    # Get choice embeddings\n",
    "    choice_embeddings = get_embeddings(choices, model_name)\n",
    "    choice_to_embedding = {choice: emb for choice, emb in zip(choices, choice_embeddings)}\n",
    "    \n",
    "    # Collect all ConceptNet concepts and their metadata\n",
    "    all_concepts = []\n",
    "    concept_metadata = []\n",
    "    \n",
    "    for relation_type, concepts in conceptnet_data.items():\n",
    "        for concept, weight in concepts:\n",
    "            all_concepts.append(concept)\n",
    "            concept_metadata.append({\n",
    "                'concept': concept,\n",
    "                'relation': relation_type,\n",
    "                'weight': weight\n",
    "            })\n",
    "    \n",
    "    # Get embeddings for all ConceptNet concepts\n",
    "    if all_concepts:\n",
    "        concept_embeddings = get_embeddings(all_concepts, model_name)\n",
    "    else:\n",
    "        concept_embeddings = []\n",
    "    \n",
    "    # Score each choice\n",
    "    choice_scores = {}\n",
    "    \n",
    "    for choice in choices:\n",
    "        choice_emb = choice_to_embedding[choice]\n",
    "        \n",
    "        # Method 1: Direct similarity between choice and question\n",
    "        direct_similarity = cosine_similarity(choice_emb, question_embedding)\n",
    "        \n",
    "        # Method 2: Similarity via ConceptNet relations\n",
    "        conceptnet_score = 0\n",
    "        matching_concepts = []\n",
    "        \n",
    "        for i, concept_emb in enumerate(concept_embeddings):\n",
    "            metadata = concept_metadata[i]\n",
    "            \n",
    "            # Similarity between choice and this concept\n",
    "            choice_concept_sim = cosine_similarity(choice_emb, concept_emb)\n",
    "            \n",
    "            # Similarity between question and this concept\n",
    "            question_concept_sim = cosine_similarity(question_embedding, concept_emb)\n",
    "            \n",
    "            # Combined score: how well this concept bridges choice and question\n",
    "            bridge_score = (choice_concept_sim * question_concept_sim * metadata['weight'])\n",
    "            \n",
    "            if bridge_score > 0.1:  # Threshold to filter noise\n",
    "                conceptnet_score += bridge_score\n",
    "                matching_concepts.append({\n",
    "                    'concept': metadata['concept'],\n",
    "                    'relation': metadata['relation'],\n",
    "                    'weight': metadata['weight'],\n",
    "                    'choice_sim': choice_concept_sim,\n",
    "                    'question_sim': question_concept_sim,\n",
    "                    'bridge_score': bridge_score\n",
    "                })\n",
    "        \n",
    "        # Combine both scores\n",
    "        total_score = direct_similarity + conceptnet_score\n",
    "        \n",
    "        choice_scores[choice] = (total_score, {\n",
    "            'direct_similarity': direct_similarity,\n",
    "            'conceptnet_score': conceptnet_score,\n",
    "            'top_concepts': sorted(matching_concepts, key=lambda x: x['bridge_score'], reverse=True)[:5]\n",
    "        })\n",
    "    \n",
    "    # Sort by score descending\n",
    "    ranked_choices = sorted(\n",
    "        [(choice, score, details) for choice, (score, details) in choice_scores.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return ranked_choices\n",
    "\n",
    "\n",
    "def rank_choices_simple_semantic(\n",
    "    conceptnet_data: Dict[str, List[Tuple[str, float]]], \n",
    "    question: str,\n",
    "    choices: List[str],\n",
    "    model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Simple version that returns just the ranked choice names.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        question: The question text\n",
    "        choices: List of answer choices to rank\n",
    "        model_name: Embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        List of choices sorted by relevance\n",
    "    \"\"\"\n",
    "    ranked = rank_choices_semantic(conceptnet_data, question, choices, model_name)\n",
    "    return [choice for choice, _, _ in ranked]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Choices (Semantic Matching):\n",
      "================================================================================\n",
      "\n",
      "1. BANK (Total Score: 0.686)\n",
      "   Direct similarity to question: 0.125\n",
      "   ConceptNet bridge score: 0.561\n",
      "   Top bridging concepts:\n",
      "   - UsedFor: 'entering building' (bridge: 0.290)\n",
      "   - RelatedTo: 'revolving doors' (bridge: 0.146)\n",
      "   - AtLocation: 'bank' (bridge: 0.125)\n",
      "\n",
      "2. MALL (Total Score: 0.453)\n",
      "   Direct similarity to question: 0.039\n",
      "   ConceptNet bridge score: 0.414\n",
      "   Top bridging concepts:\n",
      "   - UsedFor: 'entering building' (bridge: 0.267)\n",
      "   - RelatedTo: 'revolving doors' (bridge: 0.147)\n",
      "\n",
      "3. LIBRARY (Total Score: 0.349)\n",
      "   Direct similarity to question: 0.020\n",
      "   ConceptNet bridge score: 0.329\n",
      "   Top bridging concepts:\n",
      "   - UsedFor: 'entering building' (bridge: 0.194)\n",
      "   - RelatedTo: 'revolving doors' (bridge: 0.135)\n",
      "\n",
      "4. DEPARTMENT STORE (Total Score: 0.326)\n",
      "   Direct similarity to question: 0.051\n",
      "   ConceptNet bridge score: 0.275\n",
      "   Top bridging concepts:\n",
      "   - RelatedTo: 'revolving doors' (bridge: 0.139)\n",
      "   - UsedFor: 'entering building' (bridge: 0.135)\n",
      "\n",
      "5. NEW YORK (Total Score: 0.255)\n",
      "   Direct similarity to question: 0.036\n",
      "   ConceptNet bridge score: 0.219\n",
      "   Top bridging concepts:\n",
      "   - UsedFor: 'entering building' (bridge: 0.219)\n",
      "\n",
      "================================================================================\n",
      "Final ranking: ['bank', 'mall', 'library', 'department store', 'new york']\n"
     ]
    }
   ],
   "source": [
    "conceptnet_data = {\n",
    "    'RelatedTo': [('drehtÃ¼r', 1.0),\n",
    "                    ('revolving doors', 1.0),\n",
    "                    ('tourniquet', 1.0),\n",
    "                    ('bussola', 1.0)],\n",
    "    'UsedFor': [('entering building', 3.464),\n",
    "                ('enter building', 1.0),\n",
    "                ('exiting building', 1.0),\n",
    "                ('getting into building', 1.0)],\n",
    "    'AtLocation': [('lobby', 2.0),\n",
    "                    ('bank', 1.0),\n",
    "                    ('building', 1.0),\n",
    "                    ('department store', 1.0),\n",
    "                    ('entrance to building', 1.0),\n",
    "                    ('hotel lobby', 1.0),\n",
    "                    ('mall', 1.0)],\n",
    "    'Synonym': [('drehtÃ¼r', 1.0)]\n",
    "}\n",
    "\n",
    "question = \"A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\"\n",
    "choices = [\"bank\", \"library\", \"department store\", \"mall\", \"new york\"]\n",
    "\n",
    "# Get full ranking with scores\n",
    "ranked = rank_choices_semantic(conceptnet_data, question, choices)\n",
    "\n",
    "print(\"Ranked Choices (Semantic Matching):\")\n",
    "print(\"=\" * 80)\n",
    "for i, (choice, score, details) in enumerate(ranked, 1):\n",
    "    print(f\"\\n{i}. {choice.upper()} (Total Score: {score:.3f})\")\n",
    "    print(f\"   Direct similarity to question: {details['direct_similarity']:.3f}\")\n",
    "    print(f\"   ConceptNet bridge score: {details['conceptnet_score']:.3f}\")\n",
    "    \n",
    "    if details['top_concepts']:\n",
    "        print(f\"   Top bridging concepts:\")\n",
    "        for concept_info in details['top_concepts'][:3]:\n",
    "            print(f\"   - {concept_info['relation']}: '{concept_info['concept']}' \"\n",
    "                    f\"(bridge: {concept_info['bridge_score']:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Final ranking:\", rank_choices_simple_semantic(conceptnet_data, question, choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14bbdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f6086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "244e533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOFT ATTENTION RANKING\n",
      "================================================================================\n",
      "\n",
      "1. MALL (Score: 0.2353)\n",
      "   Direct similarity: 0.0394\n",
      "   Attention score: 0.3192\n",
      "   Top attended concepts:\n",
      "   - [AtLocation] 'mall'\n",
      "     (attention: 0.0541, similarity: 1.0000, contribution: 0.0541)\n",
      "   - [AtLocation] 'department store'\n",
      "     (attention: 0.0547, similarity: 0.6060, contribution: 0.0332)\n",
      "   - [AtLocation] 'hotel lobby'\n",
      "     (attention: 0.0601, similarity: 0.4122, contribution: 0.0248)\n",
      "\n",
      "2. BANK (Score: 0.2352)\n",
      "   Direct similarity: 0.1254\n",
      "   Attention score: 0.2823\n",
      "   Top attended concepts:\n",
      "   - [AtLocation] 'bank'\n",
      "     (attention: 0.0589, similarity: 1.0000, contribution: 0.0589)\n",
      "   - [RelatedTo] 'revolving doors'\n",
      "     (attention: 0.0994, similarity: 0.2250, contribution: 0.0224)\n",
      "   - [AtLocation] 'mall'\n",
      "     (attention: 0.0541, similarity: 0.3570, contribution: 0.0193)\n",
      "\n",
      "3. DEPARTMENT STORE (Score: 0.1870)\n",
      "   Direct similarity: 0.0512\n",
      "   Attention score: 0.2452\n",
      "   Top attended concepts:\n",
      "   - [AtLocation] 'department store'\n",
      "     (attention: 0.0547, similarity: 1.0000, contribution: 0.0547)\n",
      "   - [AtLocation] 'mall'\n",
      "     (attention: 0.0541, similarity: 0.6060, contribution: 0.0328)\n",
      "   - [RelatedTo] 'revolving doors'\n",
      "     (attention: 0.0994, similarity: 0.2151, contribution: 0.0214)\n",
      "\n",
      "4. LIBRARY (Score: 0.1652)\n",
      "   Direct similarity: 0.0196\n",
      "   Attention score: 0.2276\n",
      "   Top attended concepts:\n",
      "   - [AtLocation] 'mall'\n",
      "     (attention: 0.0541, similarity: 0.3915, contribution: 0.0212)\n",
      "   - [RelatedTo] 'revolving doors'\n",
      "     (attention: 0.0994, similarity: 0.2090, contribution: 0.0208)\n",
      "   - [AtLocation] 'building'\n",
      "     (attention: 0.0588, similarity: 0.3181, contribution: 0.0187)\n",
      "\n",
      "5. NEW YORK (Score: 0.1611)\n",
      "   Direct similarity: 0.0356\n",
      "   Attention score: 0.2149\n",
      "   Top attended concepts:\n",
      "   - [AtLocation] 'department store'\n",
      "     (attention: 0.0547, similarity: 0.3718, contribution: 0.0204)\n",
      "   - [AtLocation] 'mall'\n",
      "     (attention: 0.0541, similarity: 0.3641, contribution: 0.0197)\n",
      "   - [AtLocation] 'building'\n",
      "     (attention: 0.0588, similarity: 0.3084, contribution: 0.0181)\n",
      "\n",
      "================================================================================\n",
      "MULTI-HEAD ATTENTION RANKING\n",
      "================================================================================\n",
      "\n",
      "1. MALL (Score: 0.2353)\n",
      "   Direct similarity: 0.0394\n",
      "   Multi-head attention score: 0.3192\n",
      "   Individual head scores: ['0.3192', '0.3192', '0.3192', '0.3192']\n",
      "\n",
      "2. BANK (Score: 0.2352)\n",
      "   Direct similarity: 0.1254\n",
      "   Multi-head attention score: 0.2823\n",
      "   Individual head scores: ['0.2823', '0.2823', '0.2823', '0.2823']\n",
      "\n",
      "3. DEPARTMENT STORE (Score: 0.1870)\n",
      "   Direct similarity: 0.0512\n",
      "   Multi-head attention score: 0.2452\n",
      "   Individual head scores: ['0.2452', '0.2452', '0.2452', '0.2452']\n",
      "\n",
      "4. LIBRARY (Score: 0.1652)\n",
      "   Direct similarity: 0.0196\n",
      "   Multi-head attention score: 0.2276\n",
      "   Individual head scores: ['0.2276', '0.2276', '0.2276', '0.2276']\n",
      "\n",
      "5. NEW YORK (Score: 0.1611)\n",
      "   Direct similarity: 0.0356\n",
      "   Multi-head attention score: 0.2149\n",
      "   Individual head scores: ['0.2149', '0.2149', '0.2149', '0.2149']\n",
      "\n",
      "================================================================================\n",
      "Final rankings:\n",
      "Soft attention: ['mall', 'bank', 'department store', 'library', 'new york']\n",
      "Multi-head attention: ['mall', 'bank', 'department store', 'library', 'new york']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "def get_embeddings(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings to embed\n",
    "        model_name: Name of the embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute softmax values for array x.\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "\n",
    "def attention_based_ranking(\n",
    "    conceptnet_data: Dict[str, List[Tuple[str, float]]], \n",
    "    question: str,\n",
    "    choices: List[str],\n",
    "    model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ") -> List[Tuple[str, float, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Rank choices using soft attention over ConceptNet concepts.\n",
    "    \n",
    "    Method: \n",
    "    1. Compute attention weights for each concept based on question similarity\n",
    "    2. Use attention weights to aggregate choice-concept similarities\n",
    "    3. Combine with direct question-choice similarity\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        question: The question text\n",
    "        choices: List of answer choices to rank\n",
    "        model_name: Embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (choice, score, details) sorted by score descending\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    question_embedding = get_embeddings([question], model_name)[0]\n",
    "    choice_embeddings = get_embeddings(choices, model_name)\n",
    "    \n",
    "    # Collect all concepts from ConceptNet\n",
    "    all_concepts = []\n",
    "    concept_metadata = []\n",
    "    \n",
    "    for relation_type, concepts in conceptnet_data.items():\n",
    "        for concept, weight in concepts:\n",
    "            all_concepts.append(concept)\n",
    "            concept_metadata.append({\n",
    "                'concept': concept,\n",
    "                'relation': relation_type\n",
    "            })\n",
    "    \n",
    "    if not all_concepts:\n",
    "        # If no concepts, just use direct similarity\n",
    "        results = []\n",
    "        for i, choice in enumerate(choices):\n",
    "            direct_sim = cosine_similarity(question_embedding, choice_embeddings[i])\n",
    "            results.append((choice, direct_sim, {\n",
    "                'direct_similarity': direct_sim,\n",
    "                'attention_score': 0.0,\n",
    "                'top_attended_concepts': []\n",
    "            }))\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get concept embeddings\n",
    "    concept_embeddings = get_embeddings(all_concepts, model_name)\n",
    "    \n",
    "    # Compute attention weights: how relevant is each concept to the question?\n",
    "    attention_logits = np.array([\n",
    "        cosine_similarity(question_embedding, concept_emb)\n",
    "        for concept_emb in concept_embeddings\n",
    "    ])\n",
    "    attention_weights = softmax(attention_logits)\n",
    "    \n",
    "    # Rank choices\n",
    "    results = []\n",
    "    \n",
    "    for i, choice in enumerate(choices):\n",
    "        choice_emb = choice_embeddings[i]\n",
    "        \n",
    "        # Direct similarity between question and choice\n",
    "        direct_sim = cosine_similarity(question_embedding, choice_emb)\n",
    "        \n",
    "        # Attention-weighted similarity: \n",
    "        # Sum of (attention_weight * similarity_to_choice) for each concept\n",
    "        choice_concept_sims = np.array([\n",
    "            cosine_similarity(choice_emb, concept_emb)\n",
    "            for concept_emb in concept_embeddings\n",
    "        ])\n",
    "        \n",
    "        attention_score = np.sum(attention_weights * choice_concept_sims)\n",
    "        \n",
    "        # Combined score (can adjust weights)\n",
    "        total_score = 0.3 * direct_sim + 0.7 * attention_score\n",
    "        \n",
    "        # Find top attended concepts for this choice\n",
    "        concept_contributions = attention_weights * choice_concept_sims\n",
    "        top_indices = np.argsort(concept_contributions)[-5:][::-1]\n",
    "        \n",
    "        top_concepts = []\n",
    "        for idx in top_indices:\n",
    "            if concept_contributions[idx] > 0.01:  # Threshold\n",
    "                top_concepts.append({\n",
    "                    'concept': concept_metadata[idx]['concept'],\n",
    "                    'relation': concept_metadata[idx]['relation'],\n",
    "                    'attention_weight': float(attention_weights[idx]),\n",
    "                    'choice_similarity': float(choice_concept_sims[idx]),\n",
    "                    'contribution': float(concept_contributions[idx])\n",
    "                })\n",
    "        \n",
    "        results.append((choice, total_score, {\n",
    "            'direct_similarity': float(direct_sim),\n",
    "            'attention_score': float(attention_score),\n",
    "            'top_attended_concepts': top_concepts\n",
    "        }))\n",
    "    \n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def multi_head_attention_ranking(\n",
    "    conceptnet_data: Dict[str, List[Tuple[str, float]]], \n",
    "    question: str,\n",
    "    choices: List[str],\n",
    "    num_heads: int = 4,\n",
    "    model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ") -> List[Tuple[str, float, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Rank choices using multi-head attention over ConceptNet concepts.\n",
    "    \n",
    "    Args:\n",
    "        conceptnet_data: Dict mapping relation types to lists of (concept, weight) tuples\n",
    "        question: The question text\n",
    "        choices: List of answer choices to rank\n",
    "        num_heads: Number of attention heads\n",
    "        model_name: Embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (choice, score, details) sorted by score descending\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    question_embedding = get_embeddings([question], model_name)[0]\n",
    "    choice_embeddings = get_embeddings(choices, model_name)\n",
    "    \n",
    "    # Collect all concepts\n",
    "    all_concepts = []\n",
    "    concept_metadata = []\n",
    "    \n",
    "    for relation_type, concepts in conceptnet_data.items():\n",
    "        for concept, weight in concepts:\n",
    "            all_concepts.append(concept)\n",
    "            concept_metadata.append({\n",
    "                'concept': concept,\n",
    "                'relation': relation_type\n",
    "            })\n",
    "    \n",
    "    if not all_concepts:\n",
    "        results = []\n",
    "        for i, choice in enumerate(choices):\n",
    "            direct_sim = cosine_similarity(question_embedding, choice_embeddings[i])\n",
    "            results.append((choice, direct_sim, {}))\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    concept_embeddings = get_embeddings(all_concepts, model_name)\n",
    "    \n",
    "    # For simplicity, we'll use different random projections for each head\n",
    "    # In practice, you'd learn these projections\n",
    "    np.random.seed(42)\n",
    "    embedding_dim = question_embedding.shape[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, choice in enumerate(choices):\n",
    "        choice_emb = choice_embeddings[i]\n",
    "        direct_sim = cosine_similarity(question_embedding, choice_emb)\n",
    "        \n",
    "        head_scores = []\n",
    "        \n",
    "        # Compute score for each attention head\n",
    "        for head in range(num_heads):\n",
    "            # Simple projection: random permutation of embedding dimensions\n",
    "            perm = np.random.permutation(embedding_dim)\n",
    "            \n",
    "            # Project embeddings for this head\n",
    "            q_proj = question_embedding[perm]\n",
    "            c_proj = choice_emb[perm]\n",
    "            concept_projs = concept_embeddings[:, perm]\n",
    "            \n",
    "            # Compute attention weights for this head\n",
    "            attention_logits = np.array([\n",
    "                cosine_similarity(q_proj, concept_proj)\n",
    "                for concept_proj in concept_projs\n",
    "            ])\n",
    "            attention_weights = softmax(attention_logits)\n",
    "            \n",
    "            # Compute choice-concept similarities\n",
    "            choice_concept_sims = np.array([\n",
    "                cosine_similarity(c_proj, concept_proj)\n",
    "                for concept_proj in concept_projs\n",
    "            ])\n",
    "            \n",
    "            # Attention-weighted score for this head\n",
    "            head_score = np.sum(attention_weights * choice_concept_sims)\n",
    "            head_scores.append(head_score)\n",
    "        \n",
    "        # Average across heads\n",
    "        avg_attention_score = np.mean(head_scores)\n",
    "        \n",
    "        # Combined score\n",
    "        total_score = 0.3 * direct_sim + 0.7 * avg_attention_score\n",
    "        \n",
    "        results.append((choice, total_score, {\n",
    "            'direct_similarity': float(direct_sim),\n",
    "            'multi_head_attention_score': float(avg_attention_score),\n",
    "            'head_scores': [float(s) for s in head_scores]\n",
    "        }))\n",
    "    \n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    conceptnet_data = {\n",
    "        'RelatedTo': [('drehtÃ¼r', 1.0),\n",
    "                      ('revolving doors', 1.0),\n",
    "                      ('tourniquet', 1.0),\n",
    "                      ('bussola', 1.0)],\n",
    "        'UsedFor': [('entering building', 3.464),\n",
    "                    ('enter building', 1.0),\n",
    "                    ('exiting building', 1.0),\n",
    "                    ('getting into building', 1.0)],\n",
    "        'AtLocation': [('lobby', 2.0),\n",
    "                       ('bank', 1.0),\n",
    "                       ('building', 1.0),\n",
    "                       ('department store', 1.0),\n",
    "                       ('entrance to building', 1.0),\n",
    "                       ('hotel lobby', 1.0),\n",
    "                       ('mall', 1.0)],\n",
    "        'Synonym': [('drehtÃ¼r', 1.0)]\n",
    "    }\n",
    "    \n",
    "    question = \"A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\"\n",
    "    choices = [\"bank\", \"library\", \"department store\", \"mall\", \"new york\"]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"SOFT ATTENTION RANKING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ranked = attention_based_ranking(conceptnet_data, question, choices)\n",
    "    \n",
    "    for i, (choice, score, details) in enumerate(ranked, 1):\n",
    "        print(f\"\\n{i}. {choice.upper()} (Score: {score:.4f})\")\n",
    "        print(f\"   Direct similarity: {details['direct_similarity']:.4f}\")\n",
    "        print(f\"   Attention score: {details['attention_score']:.4f}\")\n",
    "        \n",
    "        if details['top_attended_concepts']:\n",
    "            print(f\"   Top attended concepts:\")\n",
    "            for concept_info in details['top_attended_concepts'][:3]:\n",
    "                print(f\"   - [{concept_info['relation']}] '{concept_info['concept']}'\")\n",
    "                print(f\"     (attention: {concept_info['attention_weight']:.4f}, \"\n",
    "                      f\"similarity: {concept_info['choice_similarity']:.4f}, \"\n",
    "                      f\"contribution: {concept_info['contribution']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MULTI-HEAD ATTENTION RANKING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ranked_multi = multi_head_attention_ranking(conceptnet_data, question, choices, num_heads=4)\n",
    "    \n",
    "    for i, (choice, score, details) in enumerate(ranked_multi, 1):\n",
    "        print(f\"\\n{i}. {choice.upper()} (Score: {score:.4f})\")\n",
    "        print(f\"   Direct similarity: {details['direct_similarity']:.4f}\")\n",
    "        print(f\"   Multi-head attention score: {details['multi_head_attention_score']:.4f}\")\n",
    "        print(f\"   Individual head scores: {[f'{s:.4f}' for s in details['head_scores']]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Final rankings:\")\n",
    "    print(\"Soft attention:\", [choice for choice, _, _ in ranked])\n",
    "    print(\"Multi-head attention:\", [choice for choice, _, _ in ranked_multi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0678c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b2c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf5a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "620a38c4",
   "metadata": {},
   "source": [
    "Embedding based Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23b9ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class ConceptNetRanker:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def _cosine(self, a, b):\n",
    "        return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0][0]\n",
    "\n",
    "    def build_conceptnet_strings(self, concept, conceptnet_data):\n",
    "        \"\"\"\n",
    "        Convert ConceptNet relations into natural-language strings.\n",
    "        Example: \"revolving door AtLocation bank\"\n",
    "        \"\"\"\n",
    "        relation_texts = []\n",
    "        for relation, targets in conceptnet_data.items():\n",
    "            for t in targets:\n",
    "                t = t[0] if isinstance(t, tuple) else t  # handle tuple (string,)\n",
    "                relation_texts.append(f\"{concept} {relation} {t}\")\n",
    "        return relation_texts\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        question: str,\n",
    "        choices: list,\n",
    "        concept: str,\n",
    "        conceptnet_data: dict,\n",
    "        w_question_choice=0.4,\n",
    "        w_choice_conceptnet=0.6,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute combined similarity score:\n",
    "        score = w1 * sim(Question, Choice) + w2 * sim(Choice, ConceptNet neighborhood)\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Step 1: encode embeddings ---\n",
    "        emb_question = self.model.encode(question)\n",
    "        emb_choices = self.model.encode(choices)\n",
    "\n",
    "        # Build ConceptNet relation sentences\n",
    "        cn_strings = self.build_conceptnet_strings(concept, conceptnet_data)\n",
    "        emb_cn = self.model.encode(cn_strings)\n",
    "\n",
    "        # --- Step 2: compute similarity ---\n",
    "\n",
    "        # A. Question â†’ Choice similarity\n",
    "        sim_QC = [self._cosine(emb_question, ec) for ec in emb_choices]\n",
    "\n",
    "        # B. Choice â†’ ConceptNet (mean similarity to all CN relation strings)\n",
    "        sim_choice_cn = []\n",
    "        for ec in emb_choices:\n",
    "            sims = cosine_similarity([ec], emb_cn)[0]\n",
    "            sim_choice_cn.append(np.mean(sims))\n",
    "\n",
    "        # --- Step 3: combine weighted scores ---\n",
    "        final_scores = []\n",
    "        for s1, s2 in zip(sim_QC, sim_choice_cn):\n",
    "            final_scores.append(w_question_choice * s1 + w_choice_conceptnet * s2)\n",
    "\n",
    "        # Return choices with scores\n",
    "        ranked = sorted(zip(choices, final_scores), key=lambda x: x[1], reverse=True)\n",
    "        return ranked, {\n",
    "            \"sim_question_choice\": sim_QC,\n",
    "            \"sim_choice_conceptnet\": sim_choice_cn,\n",
    "            \"scores\": final_scores,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "240f06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking:\n",
      "bank                  score=0.1475\n",
      "mall                  score=0.1400\n",
      "department store      score=0.1208\n",
      "library               score=0.0611\n",
      "new york              score=0.0515\n"
     ]
    }
   ],
   "source": [
    "# conceptnet_data = {\n",
    "#     'RelatedTo': [('drehtÃ¼r'), ('revolving doors'), ('tourniquet'), ('bussola')],\n",
    "#     'UsedFor': [('entering building'), ('enter building'), \n",
    "#                 ('exiting building'), ('getting into building')],\n",
    "#     'AtLocation': [('lobby'), ('bank'), ('building'), \n",
    "#                    ('department store'), ('entrance to building'), \n",
    "#                    ('hotel lobby'), ('mall')],\n",
    "#     'Synonym': [('drehtÃ¼r')]\n",
    "# }\n",
    "conceptnet_data = {'RelatedTo': [('drehtÃ¼r', 1.0),\n",
    "  ('revolving doors', 1.0),\n",
    "  ('tourniquet', 1.0),\n",
    "  ('bussola', 1.0)],\n",
    " 'UsedFor': [('entering building', 3.464),\n",
    "  ('enter building', 1.0),\n",
    "  ('exiting building', 1.0),\n",
    "  ('getting into building', 1.0)],\n",
    " 'AtLocation': [('lobby', 2.0),\n",
    "  ('bank', 1.0),\n",
    "  ('building', 1.0),\n",
    "  ('department store', 1.0),\n",
    "  ('entrance to building', 1.0),\n",
    "  ('hotel lobby', 1.0),\n",
    "  ('mall', 1.0)],\n",
    " 'Synonym': [('drehtÃ¼r', 1.0)]}\n",
    "\n",
    "question = \"A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\"\n",
    "concept = \"revolving door\"\n",
    "choices = [\n",
    "    \"bank\",\n",
    "    \"library\",\n",
    "    \"department store\",\n",
    "    \"mall\",\n",
    "    \"new york\"\n",
    "]\n",
    "\n",
    "ranker = ConceptNetRanker()\n",
    "ranked, debug = ranker.score(question, choices, concept, conceptnet_data)\n",
    "\n",
    "print(\"Ranking:\")\n",
    "for c, s in ranked:\n",
    "    print(f\"{c:20}  score={s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df6426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
