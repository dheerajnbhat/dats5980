{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c8307c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "from gradio_client import Client\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import partial\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"data/commonsenseqa_validation.json\"\n",
    "\n",
    "with open(dataset_path, \"r\") as fp:\n",
    "    csqa_dataset = json.load(fp)\n",
    "\n",
    "len(csqa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "250aaeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://cstr-conceptnet-normalized.hf.space âœ”\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"cstr/conceptnet_normalized\")\n",
    "\n",
    "relations = [\n",
    "            'RelatedTo','IsA','PartOf','HasA','UsedFor','CapableOf','AtLocation',\n",
    "            'Causes','HasSubevent','HasFirstSubevent','HasLastSubevent',\n",
    "            'HasPrerequisite','HasProperty','MotivatedByGoal','ObstructedBy',\n",
    "            'Desires','CreatedBy','Synonym','Antonym','DistinctFrom','DerivedFrom',\n",
    "            'SymbolOf','DefinedAs','MannerOf','LocatedNear','HasContext','SimilarTo',\n",
    "            'EtymologicallyRelatedTo','EtymologicallyDerivedFrom','CausesDesire',\n",
    "            'MadeOf','ReceivesAction','ExternalURL','NotDesires','NotUsedFor',\n",
    "            'NotCapableOf','NotHasProperty'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91833fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conceptnet_profile(word, relations):\n",
    "    result = client.predict(\n",
    "        word=word,\n",
    "        lang=\"en\",\n",
    "        selected_relations=relations,\n",
    "        api_name=\"/get_semantic_profile\"\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "027189ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conceptnet_profile(profile_text):\n",
    "    \"\"\"\n",
    "    Parse ConceptNet semantic profile text into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        profile_text: String output from get_conceptnet_profile\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with relation types as keys and list of (word, score) tuples as values.\n",
    "        Only includes relations that have values, sorted by score in descending order.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # Extract the queried word from the header\n",
    "    # Pattern: # ðŸ§  Semantic Profile: 'word' (EN)\n",
    "    header_match = re.search(r\"# ðŸ§  Semantic Profile: '([^']+)'\", profile_text)\n",
    "    queried_word = header_match.group(1) if header_match else None\n",
    "    \n",
    "    # Normalize the queried word for comparison (both space and underscore versions)\n",
    "    if queried_word:\n",
    "        queried_normalized_space = queried_word.replace('_', ' ')\n",
    "        queried_normalized_underscore = queried_word.replace(' ', '_')\n",
    "    else:\n",
    "        queried_normalized_space = None\n",
    "        queried_normalized_underscore = None\n",
    "    \n",
    "    # Split by relation headers (## RelationType)\n",
    "    sections = re.split(r'## (\\w+)', profile_text)\n",
    "    \n",
    "    # sections[0] is the header before first relation, then alternates between relation name and content\n",
    "    for i in range(1, len(sections), 2):\n",
    "        relation = sections[i]\n",
    "        content = sections[i + 1] if i + 1 < len(sections) else \"\"\n",
    "        \n",
    "        # Temporary list for this relation\n",
    "        relation_list = []\n",
    "        \n",
    "        # Find all relation entries\n",
    "        # Pattern: - *word1* or **word1** RelationType â†’ *word2* or **word2** `[score]`\n",
    "        pattern = r'-\\s+(?:\\*\\*?([^*]+?)\\*\\*?)\\s+\\w+\\s+â†’\\s+(?:\\*\\*?([^*]+?)\\*\\*?)\\s+`\\[([0-9.]+)\\]`'\n",
    "        matches = re.findall(pattern, content)\n",
    "        \n",
    "        for match in matches:\n",
    "            word1, word2, score = match\n",
    "            # Remove any extra whitespace\n",
    "            word1 = word1.strip()\n",
    "            word2 = word2.strip()\n",
    "            score = float(score)\n",
    "            \n",
    "            # Check if either word matches the queried word (in either format)\n",
    "            def is_queried_word(word):\n",
    "                if not queried_word:\n",
    "                    return False\n",
    "                word_space = word.replace('_', ' ')\n",
    "                word_underscore = word.replace(' ', '_')\n",
    "                return (word == queried_word or \n",
    "                        word_space == queried_normalized_space or \n",
    "                        word_underscore == queried_normalized_underscore)\n",
    "            \n",
    "            # Determine which word is NOT the queried word\n",
    "            if is_queried_word(word1):\n",
    "                target_word = word2\n",
    "            elif is_queried_word(word2):\n",
    "                target_word = word1\n",
    "            else:\n",
    "                # If neither matches exactly, prefer word1 (usually the related concept)\n",
    "                target_word = word1\n",
    "            \n",
    "            relation_list.append((target_word, score))\n",
    "        \n",
    "        # Only add to result if there are values, and sort by score descending\n",
    "        if relation_list:\n",
    "            # Sort by score (second element of tuple) in descending order\n",
    "            relation_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            result[relation] = relation_list\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ee7fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RelatedTo': [('drehtÃ¼r', 1.0),\n",
       "  ('revolving doors', 1.0),\n",
       "  ('tourniquet', 1.0),\n",
       "  ('bussola', 1.0)],\n",
       " 'UsedFor': [('entering building', 3.464),\n",
       "  ('enter building', 1.0),\n",
       "  ('exiting building', 1.0),\n",
       "  ('getting into building', 1.0)],\n",
       " 'AtLocation': [('lobby', 2.0),\n",
       "  ('bank', 1.0),\n",
       "  ('building', 1.0),\n",
       "  ('department store', 1.0),\n",
       "  ('entrance to building', 1.0),\n",
       "  ('hotel lobby', 1.0),\n",
       "  ('mall', 1.0)],\n",
       " 'Synonym': [('drehtÃ¼r', 1.0)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptnet_text = get_conceptnet_profile(\"revolving door\", relations)\n",
    "conceptnet_data = parse_conceptnet_profile(conceptnet_text)\n",
    "conceptnet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57bf31eb",
   "metadata": {},
   "source": [
    "Concepts and question concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d557076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1221/1221 [00:00<00:00, 187708.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique concepts to fetch: 4010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "concepts = []\n",
    "for data_point in tqdm(csqa_dataset):\n",
    "    choices = data_point['choices']['text']\n",
    "    question_concept = data_point['question_concept']\n",
    "\n",
    "    temp_concept = choices + [question_concept]\n",
    "    concepts.extend(temp_concept)\n",
    "\n",
    "concepts = list(set(concepts))\n",
    "print(f\"Total unique concepts to fetch: {len(concepts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453034ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptnet_relations = {}\n",
    "for concept in tqdm(concepts):\n",
    "    conceptnet_text = get_conceptnet_profile(concept, relations)\n",
    "    conceptnet_data = parse_conceptnet_profile(conceptnet_text)\n",
    "    conceptnet_relations[concept] = conceptnet_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3fdd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_conceptnet_data(concept, relations):\n",
    "    \"\"\"Helper function to fetch and parse ConceptNet data for a single concept\"\"\"\n",
    "    try:\n",
    "        conceptnet_text = get_conceptnet_profile(concept, relations)\n",
    "        conceptnet_data = parse_conceptnet_profile(conceptnet_text)\n",
    "        return concept, conceptnet_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {concept}: {e}\")\n",
    "        return concept, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7933315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/4010 [00:10<27:54,  2.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing buying products: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 101/4010 [00:47<28:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing book: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 774/4010 [05:31<18:39,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing homes: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 905/4010 [06:25<15:56,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing serious: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 1131/4010 [08:01<23:39,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing police officer: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1312/4010 [09:23<16:40,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing confusion: \n",
      "Error processing learn from each other: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1337/4010 [09:33<18:08,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing pressure: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1562/4010 [11:07<14:28,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing union: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1729/4010 [12:16<19:35,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing carrots: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1963/4010 [13:54<21:49,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing defend: \n",
      "Error processing shark: \n",
      "Error processing ocean floor: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2106/4010 [14:56<16:31,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing farmer's market: \n",
      "Error processing school students: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2437/4010 [17:16<08:25,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing bathtub: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2473/4010 [17:33<10:34,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing superhighway: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2614/4010 [18:32<09:34,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing pencil case: Error processing see side picture: \n",
      "\n",
      "Error processing playing soccer: \n",
      "Error processing releases heat: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2833/4010 [20:07<07:17,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing tree: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3054/4010 [21:43<07:10,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing delays: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3452/4010 [24:35<03:14,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing topfree: \n",
      "Error processing housing estate: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3667/4010 [26:07<02:10,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing taking tests: \n",
      "Error processing being employed: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3753/4010 [26:43<01:39,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sell products: \n",
      "Error processing bench: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4010/4010 [28:33<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "conceptnet_relations = {}\n",
    "max_workers = 5  # Adjust this number based on your needs and API limits\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Create a partial function with fixed relations parameter\n",
    "    fetch_func = partial(fetch_conceptnet_data, relations=relations)\n",
    "    \n",
    "    # Submit all tasks\n",
    "    future_to_concept = {executor.submit(fetch_func, concept): concept for concept in concepts}\n",
    "    \n",
    "    # Process completed tasks with progress bar\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_concept), total=len(concepts)):\n",
    "        concept, data = future.result()\n",
    "        conceptnet_relations[concept] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the data as needed, e.g., save to a file or database\n",
    "# with open(f\"data/conceptnet_relations.json\", \"w\") as fp:\n",
    "#     json.dump(conceptnet_relations, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea48b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"data/conceptnet_relations.json\", \"r\") as fp:\n",
    "#     conceptnet_relations = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "794e4f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4010"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conceptnet_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45831a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('being employed',\n",
       " {'Causes': [('applying for job', 1.0), ('getting contract', 1.0)]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"being employed\"\n",
    "# conceptnet_relations[concept]\n",
    "fetch_conceptnet_data(concept, relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3e222ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UsedFor': [('consumption', 2.0),\n",
       "  ('anticipated enjoyment', 1.0),\n",
       "  ('being consumer', 1.0),\n",
       "  ('filling house', 1.0),\n",
       "  ('getting food', 1.0),\n",
       "  ('getting things', 1.0),\n",
       "  ('having things', 1.0),\n",
       "  ('shopping', 1.0),\n",
       "  ('suburban shopping mall', 1.0)],\n",
       " 'Causes': [('spending money', 4.0),\n",
       "  ('spend money', 3.464),\n",
       "  ('being short on money', 2.0),\n",
       "  (\"activating country's economy\", 1.0),\n",
       "  ('agony', 1.0),\n",
       "  ('bankruptcy', 1.0),\n",
       "  ('being able to use', 1.0),\n",
       "  ('seeing exhibits', 1.0)],\n",
       " 'HasSubevent': [('compare prices', 2.0),\n",
       "  ('attending sale', 1.0),\n",
       "  ('being enticed', 1.0),\n",
       "  ('being outbid', 1.0),\n",
       "  ('break', 1.0),\n",
       "  ('carrying to car', 1.0),\n",
       "  ('check price', 1.0)],\n",
       " 'HasPrerequisite': [('money', 4.472),\n",
       "  ('cash', 1.0),\n",
       "  ('desire', 1.0),\n",
       "  ('shopping', 1.0),\n",
       "  ('shopping list', 1.0),\n",
       "  ('time', 1.0),\n",
       "  ('woman and credit card', 1.0)]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"buying products\"\n",
    "conceptnet_relations[concept] = fetch_conceptnet_data(concept, relations)[1]\n",
    "conceptnet_relations[concept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e73ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bench',\n",
       " {'RelatedTo': [('bench press', 2.0),\n",
       "   ('ØªØ®Øª', 1.0),\n",
       "   ('ØµÙØ©', 1.0),\n",
       "   ('Ù…ØµØ·Ø¨Ø©', 1.0),\n",
       "   ('Ù†Ø¶Ø¯', 1.0),\n",
       "   ('bank', 1.0),\n",
       "   ('tisch', 1.0),\n",
       "   ('sitting', 0.529),\n",
       "   ('parks', 0.418),\n",
       "   ('chair', 0.376),\n",
       "   ('sit', 0.335),\n",
       "   ('seat', 0.287),\n",
       "   ('sit on', 0.218),\n",
       "   ('place', 0.171)],\n",
       "  'IsA': [('long seat with no backrest', 2.0), ('pew', 2.0), ('sit on', 1.0)],\n",
       "  'UsedFor': [('catching breath', 1.0),\n",
       "   ('growing plants', 1.0),\n",
       "   ('legislating', 1.0),\n",
       "   ('lying down', 1.0),\n",
       "   ('observing others', 1.0),\n",
       "   ('resting', 1.0),\n",
       "   ('sit and rest', 1.0)],\n",
       "  'AtLocation': [('bus stop', 4.0),\n",
       "   ('bus depot', 3.464),\n",
       "   ('train station', 2.828),\n",
       "   ('state park', 2.0),\n",
       "   ('dugout', 1.0),\n",
       "   ('garden', 1.0),\n",
       "   ('lawn', 1.0)],\n",
       "  'Synonym': [('bank', 1.0),\n",
       "   ('sitzbank', 1.0),\n",
       "   ('bench press', 1.0),\n",
       "   ('banc', 1.0),\n",
       "   ('Ã©tabli', 1.0)],\n",
       "  'DistinctFrom': [('chair', 0.142)],\n",
       "  'DerivedFrom': [('bench press', 1.0),\n",
       "   ('bencher', 1.0),\n",
       "   ('alebench', 1.0),\n",
       "   ('backbench', 1.0),\n",
       "   ('bantling', 1.0),\n",
       "   ('bencher', 1.0),\n",
       "   ('benchland', 1.0),\n",
       "   ('benchless', 1.0),\n",
       "   ('benchlet', 1.0)],\n",
       "  'EtymologicallyRelatedTo': [('bank', 0.25),\n",
       "   ('bank', 0.25),\n",
       "   ('bench press', 0.25),\n",
       "   ('bentsh', 0.25),\n",
       "   ('bank', 0.25),\n",
       "   ('bench bleed', 0.25),\n",
       "   ('bink', 0.25),\n",
       "   ('free bench', 0.25),\n",
       "   ('×‘× ×§', 0.25)]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253235c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab08162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fd1b8f",
   "metadata": {},
   "source": [
    "concepts of keywords from question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "169988e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a02dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bring', 'umbrella', 'sunny', 'day']\n"
     ]
    }
   ],
   "source": [
    "def extract_keywords_spacy(question):\n",
    "    doc = nlp(question)\n",
    "\n",
    "    keywords = []\n",
    "    for token in doc:\n",
    "        # Filter out stopwords, punctuation, and select meaningful POS\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            if token.pos_ in {\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"}:\n",
    "                keywords.append(token.lemma_.lower())\n",
    "\n",
    "    return list(dict.fromkeys(keywords))  # Remove duplicates, preserve order\n",
    "\n",
    "\n",
    "# Example\n",
    "question = \"Why would someone bring an umbrella outside on a sunny day?\"\n",
    "print(extract_keywords_spacy(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "700bffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bring', 'umbrella', 'sunny', 'day'], ['people', 'bicycle'], ['cat', 'like', 'sit', 'warm', 'place']]\n"
     ]
    }
   ],
   "source": [
    "def extract_keywords_spacy(question):\n",
    "    doc = nlp(question)\n",
    "    return [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "        and token.pos_ in {\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"}\n",
    "    ]\n",
    "\n",
    "def extract_keywords_batch(questions, n_process=4):\n",
    "    results = []\n",
    "    for doc in nlp.pipe(questions, n_process=n_process, batch_size=32):\n",
    "        keywords = [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop\n",
    "            and not token.is_punct\n",
    "            and token.pos_ in {\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"}\n",
    "        ]\n",
    "        results.append(keywords)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "questions = [\n",
    "    \"Why would someone bring an umbrella outside on a sunny day?\",\n",
    "    \"Where do people usually keep their bicycles?\",\n",
    "    \"Why do cats like to sit in warm places?\"\n",
    "]\n",
    "\n",
    "print(extract_keywords_batch(questions, n_process=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb594af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bring', 'umbrella', 'sunny', 'day']\n"
     ]
    }
   ],
   "source": [
    "question = \"Why would someone bring an umbrella outside on a sunny day?\"\n",
    "print(extract_keywords_spacy(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 1221\n"
     ]
    }
   ],
   "source": [
    "questions = [data_point['question'] for data_point in csqa_dataset]\n",
    "\n",
    "print(f\"Total questions: {len(questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "735568be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1221/1221 [00:15<00:00, 80.08it/s]\n"
     ]
    }
   ],
   "source": [
    "question_keywords = []\n",
    "total_keywords = []\n",
    "for question in tqdm(questions):\n",
    "    keywords = extract_keywords_spacy(question)\n",
    "    question_keywords.append(keywords)\n",
    "    total_keywords.extend(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fc441aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique keywords to fetch: 2026\n"
     ]
    }
   ],
   "source": [
    "len(total_keywords)\n",
    "total_keywords = list(set(total_keywords))\n",
    "print(f\"Total unique keywords to fetch: {len(total_keywords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adfcfac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 301/2026 [02:05<11:53,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing expedite: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 474/2026 [03:15<10:19,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing cash: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2026/2026 [13:17<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use ThreadPoolExecutor for parallel processing\n",
    "conceptnet_relations = {}\n",
    "max_workers = 5  # Adjust this number based on your needs and API limits\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Create a partial function with fixed relations parameter\n",
    "    fetch_func = partial(fetch_conceptnet_data, relations=relations)\n",
    "    \n",
    "    # Submit all tasks\n",
    "    future_to_concept = {executor.submit(fetch_func, concept): concept for concept in total_keywords}\n",
    "    \n",
    "    # Process completed tasks with progress bar\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_concept), total=len(total_keywords)):\n",
    "        concept, data = future.result()\n",
    "        conceptnet_relations[concept] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9dc3e5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RelatedTo': [('money', 5.338),\n",
       "  ('payment', 1.856),\n",
       "  ('money', 1.511),\n",
       "  ('Ù†Ø¶', 1.0),\n",
       "  ('Ù†Ø¶Ø¶', 1.0),\n",
       "  ('Ù†Ù‚Ø¯', 1.0),\n",
       "  ('Ù†Ù‚Ø¯ÙŠ', 1.0),\n",
       "  ('Ù†Ù‚ÙˆØ¯', 1.0),\n",
       "  ('green', 0.291),\n",
       "  ('johnny', 0.181),\n",
       "  ('johnny precedes', 0.181),\n",
       "  ('precedes', 0.181),\n",
       "  ('bills', 0.176),\n",
       "  ('dollar', 0.176)],\n",
       " 'IsA': [('another word for money', 6.0),\n",
       "  ('money', 3.464),\n",
       "  ('another name for paper money', 2.0),\n",
       "  ('colloquialism for legal tender', 1.0),\n",
       "  ('liquid form of money', 1.0),\n",
       "  ('money in species i.e', 1.0),\n",
       "  ('paper money', 1.0),\n",
       "  ('another way to say money', 1.0),\n",
       "  ('one kind of money', 1.0)],\n",
       " 'UsedFor': [('buy things with', 2.828),\n",
       "  ('bribe', 2.0),\n",
       "  ('buy food or clothes', 1.0),\n",
       "  ('buy things', 1.0),\n",
       "  ('buying gas', 1.0),\n",
       "  ('buying items', 1.0),\n",
       "  ('buying things', 1.0),\n",
       "  ('dollar bill', 1.0)],\n",
       " 'AtLocation': [('bank', 2.0),\n",
       "  ('purse', 2.0),\n",
       "  ('cash register', 1.0),\n",
       "  ('checkstand', 1.0)],\n",
       " 'HasPrerequisite': [('buying', 1.0),\n",
       "  ('buying christmas presents', 1.0),\n",
       "  ('buying fresh fruits and vegetables', 1.0),\n",
       "  ('buying presents', 1.0),\n",
       "  ('buying products', 1.0),\n",
       "  ('cashing in', 1.0),\n",
       "  ('paying bills', 1.0)],\n",
       " 'HasProperty': [('easy to count', 1.0)],\n",
       " 'MotivatedByGoal': [('wait tables', 1.0)],\n",
       " 'Synonym': [('bargeld', 1.0),\n",
       "  ('barschaft', 1.0),\n",
       "  ('barzahlung', 1.0),\n",
       "  ('kasse', 1.0),\n",
       "  ('dead presidents', 1.0),\n",
       "  ('dosh', 1.0),\n",
       "  ('money', 1.0),\n",
       "  ('cash', 0.5)],\n",
       " 'DerivedFrom': [('cashability', 1.0),\n",
       "  ('cashable', 1.0),\n",
       "  ('cashbook', 1.0),\n",
       "  ('cashbox', 1.0),\n",
       "  ('cashectomy', 1.0),\n",
       "  ('casher', 1.0),\n",
       "  ('cashgate', 1.0)],\n",
       " 'EtymologicallyRelatedTo': [('kirch', 0.25),\n",
       "  ('kirsch', 0.25),\n",
       "  ('case', 0.25),\n",
       "  ('cashier', 0.25),\n",
       "  ('capio', 0.25)],\n",
       " 'EtymologicallyDerivedFrom': [('capsa', 1.0)],\n",
       " 'CausesDesire': [('pass university exams', 1.0), ('return to work', 1.0)],\n",
       " 'ReceivesAction': [('denominated in dollars', 1.0),\n",
       "  ('earned', 1.0),\n",
       "  ('measured in dollars and cents', 1.0)]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"cash\"\n",
    "conceptnet_relations[concept] = fetch_conceptnet_data(concept, relations)[1]\n",
    "conceptnet_relations[concept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ff48b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/conceptnet_relations.json\", \"r\") as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9458efac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5230"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = {**data, **conceptnet_relations}\n",
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"data/conceptnet_relations.json\", \"w\") as fp:\n",
    "#     json.dump(final_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480c671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd5777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5079a238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RelatedTo': [('cut', 4.984),\n",
       "  ('paper', 1.197),\n",
       "  ('Ù…Ù‚Øµ', 1.0),\n",
       "  ('schere', 1.0),\n",
       "  ('binary noun', 1.0),\n",
       "  ('chisel', 1.0),\n",
       "  ('cut', 1.0),\n",
       "  ('cutting', 0.921),\n",
       "  ('blades', 0.33),\n",
       "  ('two', 0.33),\n",
       "  ('two blades', 0.33),\n",
       "  ('cutting tool', 0.265),\n",
       "  ('tool', 0.265),\n",
       "  ('paper', 0.181)],\n",
       " 'IsA': [('clippers', 1.0), ('safety scissors', 1.0)],\n",
       " 'UsedFor': [('cut', 5.657),\n",
       "  ('construction paper', 1.0),\n",
       "  ('cut hair', 1.0),\n",
       "  ('cut leather', 1.0),\n",
       "  ('cut paper or cloth', 1.0),\n",
       "  ('cut paper snowflakes', 1.0),\n",
       "  ('cut ribbons', 1.0)],\n",
       " 'CapableOf': [('cut paper', 5.292),\n",
       "  ('become blunt', 1.0),\n",
       "  ('cut cardboard', 1.0),\n",
       "  ('part paper', 1.0),\n",
       "  ('tear cloth', 1.0),\n",
       "  ('tear paper', 1.0)],\n",
       " 'AtLocation': [('desk', 3.464),\n",
       "  ('cabinet', 2.0),\n",
       "  ('backpack', 1.0),\n",
       "  ('drawer', 1.0),\n",
       "  ('house', 1.0)],\n",
       " 'HasPrerequisite': [('going to get haircut', 2.828),\n",
       "  ('cutting hair', 2.0),\n",
       "  ('having haircut', 2.0)],\n",
       " 'HasProperty': [('sharp', 2.0), ('useful for cutting things', 1.0)],\n",
       " 'Synonym': [('pair of scissors', 2.0),\n",
       "  ('ciseau', 1.0),\n",
       "  ('ciseaux', 1.0),\n",
       "  ('paire de ciseaux', 1.0),\n",
       "  ('scissors', 0.5),\n",
       "  ('Ù…Ù‚Øµ', 0.5),\n",
       "  ('schere', 0.5),\n",
       "  ('scissors', 0.5)],\n",
       " 'Antonym': [('paper', 0.455)],\n",
       " 'DerivedFrom': [('microscissors', 1.0), ('scissorstail', 1.0)],\n",
       " 'EtymologicallyRelatedTo': [('chisel', 0.25),\n",
       "  ('excise', 0.25),\n",
       "  ('caedo', 0.25),\n",
       "  ('caesus', 0.25),\n",
       "  ('cisoria', 0.25),\n",
       "  ('cisorium', 0.25),\n",
       "  ('scindo', 0.25),\n",
       "  ('grafting scissors', 0.25),\n",
       "  ('sciss', 0.25),\n",
       "  ('scissile', 0.25),\n",
       "  ('scissor', 0.25),\n",
       "  ('tweezers', 0.25),\n",
       "  ('cesoia', 0.25)],\n",
       " 'MadeOf': [('metal', 1.0)],\n",
       " 'ReceivesAction': [('used to cut', 1.0)]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"scissors\"\n",
    "fetch_conceptnet_data(concept, relations)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
